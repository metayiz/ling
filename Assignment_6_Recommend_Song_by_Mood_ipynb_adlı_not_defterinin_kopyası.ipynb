{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "959239f6-93ce-4473-af2f-804f35583a6d",
      "metadata": {
        "id": "959239f6-93ce-4473-af2f-804f35583a6d"
      },
      "outputs": [],
      "source": [
        "# Run this block first!\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.metrics import pairwise_distances"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Steps to get the data:\n",
        "# 1. Go to the link: https://drive.google.com/drive/folders/1ZNKHlrBxqbePdNElohyMtVgrWNaKFQhD?usp=sharing\n",
        "# 2. Click on the folder name and click to `Copy to Drive` option (copy to root folder!)\n",
        "# 3. Then give permissions after running this line\n",
        "# 4. After giving permission, run the next line to copy files to your collab session.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEbKZbTV6uFX",
        "outputId": "33f5b312-1450-4750-f3d0-ff36b4b6a239"
      },
      "id": "FEbKZbTV6uFX",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "734df355-7c5a-4df1-ac79-68a7ec59d6f9",
      "metadata": {
        "id": "734df355-7c5a-4df1-ac79-68a7ec59d6f9"
      },
      "source": [
        "# <font color='#FFBD33'>**Assignment 6 - Recommend Song by Mood**</font> \n",
        "\n",
        "This is the <font color='cyan'>Assignment 6</font> for the LING360 - Computational Methods in Lingustics course and it is worth a total of  <font color='cyan'>**10 points** + **5 points (Bonus)**</font>.\n",
        "\n",
        "In this assignment, we are going to create a novel application, which is a song recommender website which will recommend a list of songs generated on the spot using the emotion detection model and text similarity.\n",
        "\n",
        "Our general plan is to:\n",
        "1. Train an **emotion detection model**\n",
        "2. Find emotions in **a song corpus**\n",
        "3. Implement **web app** which can recommend songs by looking at the **similarity between input text and songs**. Similarity metrics are going to be the\n",
        "    1. Emotion vector similarity    \n",
        "    1. Count vector similarity\n",
        "\n",
        "The topics include:\n",
        "1. Naive Bayes\n",
        "2. Streamlit\n",
        "\n",
        "\n",
        "There's a total of  <font color='cyan'>**2 main tasks**</font> and <font color='cyan'>**x subs tasks**</font>. For each task, please write your code between the following lines:\n",
        "\n",
        "```\n",
        "## YOUR CODE STARTS\n",
        "\n",
        "\n",
        "\n",
        "## YOUR CODE ENDS\n",
        "```\n",
        "\n",
        "Before working on the assignment, please copy this notebook to your own drive. You can use ```Save a copy in Drive``` under the ```File``` menu on top left.\n",
        "\n",
        "Please, run every cell in your code to make sure that it works properly before submitting it. \n",
        "\n",
        "Once you are ready to submit, download two versions of your code:\n",
        "\n",
        "*   Download .ipynb\n",
        "*   Download .py\n",
        "\n",
        "These are both available under the ```File``` menu on top left. \n",
        "\n",
        "Then, compress your files (zip, rar, or whatever) and upload the compressed file to Moodle.\n",
        "\n",
        "If you have any questions, please contact with karahan.sahin@boun.edu.tr\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp \"/content/drive/MyDrive/Assignment 6/main.py\" -t .\n",
        "! cp \"/content/drive/MyDrive/Assignment 6/song_dataset.csv\" -t .\n",
        "! cp \"/content/drive/MyDrive/Assignment 6/train_emotion.csv\" -t .\n",
        "! cp \"/content/drive/MyDrive/Assignment 6/test_emotion.csv\" -t ."
      ],
      "metadata": {
        "id": "pogH4eIdFQyZ"
      },
      "id": "pogH4eIdFQyZ",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2f89b92f-de16-49c8-ba3c-f839ff059a35",
      "metadata": {
        "tags": [],
        "id": "2f89b92f-de16-49c8-ba3c-f839ff059a35"
      },
      "source": [
        "## <font color='#FFBD33'>**Q1:** Emotion Classifier</font> `10 points`\n",
        "\n",
        "Train a model for emotion recognition using Naive Bayes Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31662a0-05af-44bd-8e26-3f99e61dcb48",
      "metadata": {
        "id": "e31662a0-05af-44bd-8e26-3f99e61dcb48"
      },
      "source": [
        "### <font color='#FFBD33'>Q1.1: Import and Clean Data</font> `2 points`\n",
        "\n",
        "First we need to get our data and preprocess it accordingly.\n",
        "\n",
        "<font color='#FFBD33'>**Instructions:**</font>\n",
        "\n",
        "1. Import train and test sets namely, `train_emotion.csv` and `test_emotion.csv`.\n",
        "2. Read line by line to get (sentence, label) pairs by separating each line with `\\t` character.\n",
        "2. For training data, add sentences to a variable called `train_sentences` and add labels to a variable called `train_labels`.\n",
        "2. For test data, add sentences to a variable called `test_sentences` and add labels to a variable called `test_labels`.\n",
        "3. Then translate the numeric labels into names `{ 0: \"sadness\", 1: \"joy\" , 2:  \"love\" , 3: \"anger\", 4: \"fear\", 5: 'surprise'}` for train and test labels.\n",
        "\n",
        "<font color='#FFBD33'>**Notes:**</font>\n",
        "\n",
        "1. Don't forget to open your file with `encoding=\"utf-8\"` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "98478531-26dd-4338-83a4-4421c9079f59",
      "metadata": {
        "tags": [],
        "id": "98478531-26dd-4338-83a4-4421c9079f59"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE STARTS\n",
        "\n",
        "train_file = \"train_emotion.csv\"\n",
        "test_file = \"test_emotion.csv\"\n",
        "\n",
        "train_sentences = []\n",
        "train_labels = []\n",
        "test_sentences = []\n",
        "test_labels = []\n",
        "\n",
        "label_mapping = {\"sadness\": 0, \"joy\": 1, \"love\": 2, \"anger\": 3, \"fear\": 4, \"surprise\": 5}\n",
        "\n",
        "with open(train_file, \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        sentence, label = line.strip().split(\"\\t\")\n",
        "        train_sentences.append(sentence)\n",
        "        train_labels.append(label_mapping[label])\n",
        "\n",
        "with open(test_file, \"r\", encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        sentence, label = line.strip().split(\"\\t\")\n",
        "        test_sentences.append(sentence)\n",
        "        test_labels.append(label_mapping[label])\n",
        "\n",
        "\n",
        "## YOUR CODE ENDS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "551fdb51-4b36-4072-93c2-39e84b620ddc",
      "metadata": {
        "id": "551fdb51-4b36-4072-93c2-39e84b620ddc"
      },
      "source": [
        "### <font color='#FFBD33'>Q1.2: Train Model/Vectorizer</font> `3 points`\n",
        "\n",
        "Process the train and test datasets and train your Naive Bayes model with train set.\n",
        "\n",
        "<font color='#FFBD33'>**Instructions:**</font>\n",
        "\n",
        "2. Then using `bow.fit_transform()` method, fit the `train_sentences` and assign it into a variable called `X_train`\n",
        "3. Generate an instance of `MultinomialNB()` object, and assign it into a variable called `model`\n",
        "4. Then using `model.fit()` method, fit the `X_train` and `train_labels`.\n",
        "5. Finally run the last line to see your model results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3fbc87c2-1f2f-485b-afa9-c7a7497ce337",
      "metadata": {
        "id": "3fbc87c2-1f2f-485b-afa9-c7a7497ce337",
        "outputId": "31851474-cf1a-47ce-c42d-10b7127fb234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "## YOUR CODE STARTS\n",
        "\n",
        "bow = CountVectorizer()\n",
        "X_train = bow.fit_transform(train_sentences)\n",
        "\n",
        "model = MultinomialNB()\n",
        "\n",
        "model.fit(X_train, train_labels)\n",
        "## YOUR CODE ENDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "70b128fe-86c3-4854-ad85-e9046acfc6e6",
      "metadata": {
        "id": "70b128fe-86c3-4854-ad85-e9046acfc6e6",
        "outputId": "71c9e47e-0d64-4260-9f09-e847ff0a04dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.93      0.82      1959\n",
            "           1       0.71      0.96      0.81      2192\n",
            "           2       0.88      0.21      0.34       547\n",
            "           3       0.91      0.55      0.68       912\n",
            "           4       0.86      0.51      0.64       749\n",
            "           5       1.00      0.02      0.05       241\n",
            "\n",
            "    accuracy                           0.74      6600\n",
            "   macro avg       0.85      0.53      0.56      6600\n",
            "weighted avg       0.78      0.74      0.71      6600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_test = bow.transform(test_sentences)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(test_labels, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fad65a4-82c3-4b45-bc0c-7ad8600b6ce7",
      "metadata": {
        "id": "6fad65a4-82c3-4b45-bc0c-7ad8600b6ce7"
      },
      "source": [
        "### <font color='#FFBD33'>Q1.3: Run on Song Corpus</font> `2 points`\n",
        "\n",
        "Use emotion detection to find the emotions of songs in corpus. Using that model, we are going to emotion features for each song.\n",
        "\n",
        "<font color='#FFBD33'>**Instructions:**</font>\n",
        "\n",
        "1. Import train and test sets namely, `song_dataset.csv`.\n",
        "2. Read line by line to get (song_name, lyrics) pairs by separating each line with `\\t` character\n",
        "2. For song data, add song_name to a variable called `song_titles` and add lyrics to a variable called `song_lyrics`.\n",
        "3. Then using `bow.transform()` method, fit the `song_lyrics` and assign it into a variable called `X_text`\n",
        "4. Then using `model.predict_proba()` method, predict the `song_lyrics` and assign it into variable called `X_mood`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ce6c7b4e-62db-4312-9680-4a8fa6919877",
      "metadata": {
        "id": "ce6c7b4e-62db-4312-9680-4a8fa6919877",
        "outputId": "f2f61f72-7a64-4395-ad1b-2664b4c05021",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.21170078e-01 5.21180504e-01 1.34826548e-02 2.36264742e-02\n",
            "  2.04338778e-02 1.06410642e-04]\n",
            " [4.06675570e-01 1.03311494e-01 6.89331113e-03 4.36998612e-01\n",
            "  4.45664929e-02 1.55452033e-03]\n",
            " [7.32605983e-01 1.32374041e-01 5.08793669e-03 7.07038448e-02\n",
            "  5.69751005e-02 2.25309388e-03]]\n"
          ]
        }
      ],
      "source": [
        "example_sentences = [\n",
        "    \"I don't know you, but it will be okay\", \n",
        "    \"I am so angry today\", \n",
        "    \"Really sad day:( \"\n",
        "]\n",
        "X_example = bow.transform(example_sentences)\n",
        "print(model.predict_proba(X_example))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6015544b-0407-440e-ad60-a6b4fc49f9a9",
      "metadata": {
        "id": "6015544b-0407-440e-ad60-a6b4fc49f9a9"
      },
      "source": [
        "As you can see, now our feature vectors are become the emotion scores extracted from the trained Naive Bayes Model\n",
        "\n",
        "|sentence       |   anger      |   fear       |      joy       |     love       |    sadness     |   surprise    |\n",
        "|--------------|--------------|--------------|----------------|----------------|----------------|---------------|\n",
        "|I don't know you, but it will be okay|2.35078678e-02|2.04108623e-02| 5.20536354e-01 | 1.34679763e-02 | 4.21970631e-01 | 1.06308399e-04|\n",
        "|I am so angry today|4.37101484e-01|4.45618521e-02| 1.03295068e-01 | 6.89272322e-03 | 4.06594385e-01 | 1.55448722e-03|\n",
        "|Really sad day:( |7.06614679e-02|5.69343769e-02| 1.32273982e-01 | 5.08437190e-03 | 7.32794178e-01 | 2.25162335e-03|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "ef307c0b-ad76-4198-b3c4-d18051eb6100",
      "metadata": {
        "id": "ef307c0b-ad76-4198-b3c4-d18051eb6100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cd0ed1-fbd2-48c3-9673-15e297e3e96c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.45387823e-01 2.54612177e-01 8.85658367e-34 2.14061641e-20\n",
            "  5.60192059e-29 9.55787264e-68]\n",
            " [7.93720318e-04 9.99059590e-01 1.46689298e-04 7.52722096e-10\n",
            "  9.15043217e-14 7.84270612e-33]\n",
            " [6.11486922e-05 9.99938851e-01 2.07527598e-14 4.24832471e-13\n",
            "  1.79697776e-21 1.00558100e-39]\n",
            " ...\n",
            " [5.04655821e-04 9.99447987e-01 1.45247034e-07 4.71797850e-05\n",
            "  3.21126255e-08 6.26063331e-12]\n",
            " [1.48189482e-03 5.70847244e-01 3.93823231e-01 9.04482643e-03\n",
            "  2.48028031e-02 1.92763207e-26]\n",
            " [1.78062355e-14 1.00000000e+00 1.85331562e-31 3.68633452e-23\n",
            "  5.97392970e-35 3.68988642e-96]]\n"
          ]
        }
      ],
      "source": [
        "## YOUR CODE STARTS\n",
        "\n",
        "import csv\n",
        "\n",
        "song = \"song_dataset.csv\"\n",
        "\n",
        "song_titles = []\n",
        "song_lyrics = []\n",
        "\n",
        "with open(song, \"r\", encoding=\"utf-8\") as file:\n",
        "    reader = csv.reader(file, delimiter=\"\\t\")\n",
        "    for line in reader:\n",
        "        song_name, lyrics = line\n",
        "        song_titles.append(song_name)\n",
        "        song_lyrics.append(lyrics)\n",
        "\n",
        "X_text = bow.transform(song_lyrics)\n",
        "\n",
        "X_mood = model.predict_proba(X_text)\n",
        "print(X_mood)\n",
        "\n",
        "## YOUR CODE ENDS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02fc4938-b839-4a24-b0c9-0c70ef54aebc",
      "metadata": {
        "id": "02fc4938-b839-4a24-b0c9-0c70ef54aebc"
      },
      "source": [
        "### <font color='#FFBD33'>Q1.4: Recommend Song with Metrics</font> `2 points`\n",
        "\n",
        "Calculate scores of song corpus and get highest scoring topK songs for given sentence.\n",
        "\n",
        "<font color='#FFBD33'>**Instructions:**</font>\n",
        "\n",
        "1. First transform your text into bow features and assign it into a variable called `x_text`\n",
        "2. Then predict its emotion features using `.predict_proba()` and assign it into a variable called `x_mood`\n",
        "3. Then extract the similarities emotion scores `input_text`, namely `x_mood` between all songs `X_mood`  using `calculateSimilarity()` and assign it to variable called `sim_mood`\n",
        "3. Then extract the similarities bow scores `input_text`, namely `x_text` between all songs `X_text`  using `calculateSimilarity()` and assign it to variable called `sim_text`\n",
        "4. The create an empty list called `mean_scores`\n",
        "5. Then using `zip()`, zip mood and text scores, and iterate over scores to calculate mean score\n",
        "    ```python\n",
        "    list1 = [1,2,3]\n",
        "    list2 = [4,5,6]\n",
        "    list(zip(list1, list2))\n",
        "    # Output: [ (1,4), (2,5), (3,6) ] \n",
        "    ```\n",
        " \n",
        "6. Then zip the song_names and mean scores, turn the zip object into a dictionary, and sort them by the descending score values.\n",
        "7. Finally return the `topk` keys of `sorted_scores` dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "83dfc146-bec7-4885-80c5-9f11069b5a1e",
      "metadata": {
        "id": "83dfc146-bec7-4885-80c5-9f11069b5a1e"
      },
      "outputs": [],
      "source": [
        "def calculateSimilarity(document_vector, all_vectors):\n",
        "    \"\"\"The function that checks similarity between input and all instance of features of corpus\n",
        "    \n",
        "    \"\"\"\n",
        "    return (1 - pairwise_distances(all_vectors,document_vector, metric=\"cosine\")).T[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "8703a020-8739-4d7c-94a8-9ea1edae4e04",
      "metadata": {
        "tags": [],
        "id": "8703a020-8739-4d7c-94a8-9ea1edae4e04"
      },
      "outputs": [],
      "source": [
        "def getSongRecommendation(text, topK=10):\n",
        "    \"\"\"Function returns a \n",
        "    \n",
        "    :args:\n",
        "        text (str): text of explaining current mood\n",
        "        topK (int): number of song titles to be returned\n",
        "        \n",
        "    :returns:\n",
        "        top_tracks (list): list containing `topK` number of song titles\n",
        "    \"\"\"\n",
        "    \n",
        "    ## YOUR CODE STARTS\n",
        "    \n",
        "    x_text = bow.transform([text])\n",
        "    x_mood = model.predict_proba(x_text)\n",
        "\n",
        "    sim_mood = calculateSimilarity(x_mood, X_mood)\n",
        "    sim_text = calculateSimilarity(x_text, X_text)\n",
        "    \n",
        "    mean_scores = []\n",
        "    \n",
        "    for mood_score, text_score in list(zip(sim_mood, sim_text)):\n",
        "      mean_score = (mood_score + text_score) / 2\n",
        "      mean_scores.append(mean_score)\n",
        "    \n",
        "    sorted_scores = sorted(zip(song_titles, mean_scores), key=lambda x: x[1], reverse=True)\n",
        "    top_tracks = sorted_scores[:topK]\n",
        "\n",
        "    ## YOUR CODE ENDS\n",
        "    \n",
        "    return top_tracks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "0ff7002a-24d9-4f35-8c95-68b54072d3e2",
      "metadata": {
        "id": "0ff7002a-24d9-4f35-8c95-68b54072d3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "c7e1e665-4333-4bc2-d5de-4f370ec85ee5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-89428a794ca1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m assert getSongRecommendation(\"\"\"Very angry, want to punch everything\"\"\") == [\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'I Want To Be Old - The Cure'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4865881400301677\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"Somebody's Everything - Dolly Parton\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.46629072991070464\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"Don't Wanna - Electric Light Orchestra\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.46627239736234016\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'Cross Oceans - First Aid Kit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.46423834544262976\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "assert getSongRecommendation(\"\"\"Very angry, want to punch everything\"\"\") == [\n",
        "    ('I Want To Be Old - The Cure', 0.4865881400301677), \n",
        "    (\"Somebody's Everything - Dolly Parton\", 0.46629072991070464), \n",
        "    (\"Don't Wanna - Electric Light Orchestra\", 0.46627239736234016), \n",
        "    ('Cross Oceans - First Aid Kit', 0.46423834544262976), \n",
        "    ('Kill Everybody - Skrillex', 0.45675276421899946), \n",
        "    ('Stand By - Jeremy Camp', 0.4564354645876385), \n",
        "    ('Without Reason - The Fray', 0.4543368996115371), \n",
        "    ('Slug - U2', 0.451413762608203), \n",
        "    ('Sundress - Ben Kweller', 0.4478342947514802), \n",
        "    ('Rock Star - Everclear', 0.4448005087202802)\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "193b6d7f-c4d2-478e-acb5-0ed2f5359305",
      "metadata": {
        "tags": [],
        "id": "193b6d7f-c4d2-478e-acb5-0ed2f5359305"
      },
      "source": [
        "## <font color='#FFBD33'>**BONUS:** Show on Streamlit</font> `5 points`\n",
        "\n",
        "Use Streamlit to showcase what your model can do! The design is shown below:\n",
        "\n",
        "<img src=\"https://lh3.googleusercontent.com/drive-viewer/AFGJ81ogzqu5cYKmGwe439OsZpByzxQqU5yxLl9_89Wo1IEcC0GOfzR7iW7dCq_mLQsG4Tr6nnFQZF40iYuWl4Zs1EBUQLIxPA=s1600\" width=\"400\" height=\"300\"/>\n",
        "\n",
        "<font color='#FFBD33'>**Instructions:**</font>\n",
        "\n",
        "1. Click on `main.py` file\n",
        "1. Run lines below.\n",
        "1. Then generate user interface according to the instructions in the file and the mockup above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "519d750f-5f4e-4f27-87a5-52268e7a8510",
      "metadata": {
        "id": "519d750f-5f4e-4f27-87a5-52268e7a8510",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f49209-99b2-4f5b-f37a-55d97de2f690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `\"install streamlit pyngrok --quiet\"'\n",
            "/bin/bash: -c: line 0: `pip(\"install streamlit pyngrok --quiet\")'\n"
          ]
        }
      ],
      "source": [
        ";!pip install streamlit pyngrok --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "9f000f6a-dea5-4ed9-834a-770e53347a66",
      "metadata": {
        "id": "9f000f6a-dea5-4ed9-834a-770e53347a66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "581119dc-92a1-43be-bb68-640b09680c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (6.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"\") # Add your auth token in here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "a7fd6c4a-f748-4d04-896a-dfab859f4276",
      "metadata": {
        "id": "a7fd6c4a-f748-4d04-896a-dfab859f4276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c01babde-ce89-4bae-f669-898248d20a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: streamlit: command not found\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.284s\n",
            "your url is: https://cruel-spoons-wash.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run /content/main.py --server.port 8000 & npx localtunnel --port 8000"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}